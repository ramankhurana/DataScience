{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aee9aab",
   "metadata": {},
   "source": [
    "# Housing price prediction \n",
    "This is second part of the California housing price prediction problem. In the first part I have explained how to perform end-to-end machine learning algorithm, and make prediction. \n",
    "\n",
    "\n",
    "\n",
    "This notebook is mainly about how to automate the preprocessing and test various models to find the best one for our case. Detailed EDA and feature enginnering is explained in the previous NB, so let's directly jump on to dataset and implement the transformers and pipeline to automate the processing post EDA. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3104c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import sklearn \n",
    "from sklearn.model_selection import StratifiedShuffleSplit \n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer, OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4837349e",
   "metadata": {},
   "source": [
    "## Load Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "499c3197",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"housing.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f837ed6",
   "metadata": {},
   "source": [
    "#### Stratified splitting \n",
    " - In the very begining I am using the stratified splitting for the reason explained in previous NB. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf0e87d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"income_category\"] = np.ceil (df.median_income/1.5)\n",
    "df['income_category'] = df[\"income_category\"].where(df.income_category<5, 5.0)\n",
    "\n",
    "\n",
    "split = StratifiedShuffleSplit (n_splits=1, \n",
    "                       test_size=0.2,\n",
    "                       random_state=42)\n",
    "\n",
    "for train_idx, test_idx in  split.split(df, df['income_category']):\n",
    "    strat_train = df.loc[train_idx]\n",
    "    strat_test  = df.loc[test_idx]\n",
    "\n",
    "Y_train, Y_test = strat_train.median_house_value, strat_test.median_house_value\n",
    "\n",
    "for strat in strat_train, strat_test: \n",
    "    strat.drop([\"income_category\",\"median_house_value\"],axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a398edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "       'total_bedrooms', 'population', 'households', 'median_income',\n",
       "       'ocean_proximity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a67c266",
   "metadata": {},
   "source": [
    "## Transformer \n",
    "Let's encapsulate custom cleanup, feature engineering in a custom class which will do the job seamlessly with sklearn functionalities like pipeline etc. \n",
    " BaseEstimator, TransformerMixin are two sklearn classes which are needed to get get_param(),set_param() functions and fit_transform() respectively. \n",
    " \n",
    " - For now, check the column number in the dataframe which we need for feature engineering, we will need an automatic way to do so in future. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf9ef032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin \n",
    "rooms_ix, bedrooms_ix, population_ix, household_ix = 3,4,5,6 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf598eb",
   "metadata": {},
   "source": [
    "##### Content of pipeline \n",
    "In order to preprocess the data we need to perform a series of tasks in a specific order and this can be partially done by a custom transformer class like below in collaboration with sklean pipelines as shown in following cells. \n",
    "The main tasks to be performed are: \n",
    " - cleaning of the dataset, nonnull, treatment of the missing values etc \n",
    " - adding more features based on the existing ones, \n",
    "   - numerical features \n",
    "   - treatment of the categorical features \n",
    " - scaling the columns to normalised values, using minmaxscaler or standardscaler or any other customized scaler. \n",
    " - any other task needs to be performed on the new data will enter this pipeline. \n",
    " \n",
    " Let's implement one easy pipeline for the linear regression and then use it for various models, and embrace the power of this tool. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "950bcf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedroom_per_room=True): ## this does not need arga and kargs \n",
    "        self.add_bedroom_per_room = add_bedroom_per_room\n",
    "    def fit(self,X,y=None):\n",
    "        return self ## in fit function nothing else needs to be done \n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:,rooms_ix] / X[:,household_ix]\n",
    "        population_per_household = X[:,population_ix] / X[:,household_ix]\n",
    "        if self.add_bedroom_per_room:\n",
    "            bedrooms_per_room = X[:,bedrooms_ix] / X[:,rooms_ix]\n",
    "            return np.c_[X,rooms_per_household, population_per_household,bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X,rooms_per_household, population_per_household]\n",
    "\n",
    "\n",
    "attr_adder = CombinedAttributesAdder(add_bedroom_per_room=False)\n",
    "train_df_extra = attr_adder.transform(strat_train.values) ## this return a numpy 2d array. this needs to be converted to dataframe\n",
    "\n",
    "cols = strat_train.columns.tolist() +[\"rooms_per_household\",\"population_per_household\"]\n",
    "train_df_extra_  = pd.DataFrame(train_df_extra,columns=cols)\n",
    "train_df_extra_\n",
    "\n",
    "\n",
    "## This class will return the values of the Dataframe for given columns. \n",
    "## this is also a transformer \n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attributes_names):\n",
    "        self.attributes_names = attributes_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    def transform(self, X,y=None):\n",
    "        #print (\"selecting\", self.attributes_names)\n",
    "        #print (X[self.attributes_names].values.shape )\n",
    "        return X[self.attributes_names].values \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "acf0dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_cat = strat_train[[\"ocean_proximity\"]] ## only categorical features \n",
    "strat_train_num = strat_train.drop([\"ocean_proximity\"],axis=1) ## need only numerical data \n",
    "\n",
    "from sklearn.pipeline import FeatureUnion \n",
    "from sklearn.pipeline import Pipeline\n",
    "num_attr = list(strat_train_num.columns)\n",
    "cat_attr = list(strat_train_cat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "185a8d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('selector',DataFrameSelector(num_attr)),\n",
    "     ('imputer',SimpleImputer (strategy=\"median\")),\n",
    "     ('add_features',CombinedAttributesAdder(False)),\n",
    "    ('std_scaler',StandardScaler()),\n",
    "     ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('selector',DataFrameSelector(cat_attr)),\n",
    "     ('dummies',OneHotEncoder(sparse=False)),\n",
    "     ])\n",
    "\n",
    "\n",
    "full_pipeline = FeatureUnion (transformer_list=[\n",
    "    ('num_pipeline',num_pipeline),\n",
    "    ('cat_pipeline',cat_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "40b823e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_trans = full_pipeline.fit_transform(strat_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c225ba",
   "metadata": {},
   "source": [
    "### Outcome \n",
    "As we can see, with the usage of transformer class and pipelines, we can make our life easier for data prepration. The data needed for model training is ready quickly with this approach and also easily scalable. \n",
    " - Let's try to train the model using this transformed dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2b469c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68911.7605423384"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "regr = LinearRegression()\n",
    "result = regr.fit(strat_train_trans,Y_train)\n",
    "np.sqrt(mean_squared_error(Y_train, result.predict(strat_train_trans)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "95c56e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     16512.000000\n",
       "mean     206990.920724\n",
       "std      115703.014830\n",
       "min       14999.000000\n",
       "25%      119800.000000\n",
       "50%      179500.000000\n",
       "75%      263900.000000\n",
       "max      500001.000000\n",
       "Name: median_house_value, dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a46013",
   "metadata": {},
   "source": [
    "#### Quick summary \n",
    "  - We implemented transformer classes to do specific tasks for the data preprocessing \n",
    "  - combined them with other preprocessing tasks into a pipelie. \n",
    "  - By calling the pipiline fit_transform function the data is ready to be feed into any desirable model we want to try for a given problem. \n",
    "  - In the example here, we have one hyperparameter of class CombinedAttributesAdder, which can be used to add a given column in the dataset or not, similarly we can have any number of configurable hyperparameters and make optimistion and testing an easy task. \n",
    "  - Here in the linear regression we used the default value of `add_bedroom_per_room` which is True, we can easily remove this variable and train again to see the change in results. \n",
    "    - The variable can be easily removed from the training by using `CombinedAttributesAdder(False)),` instead of default value `True` for the `add_bedroom_per_room`. \n",
    "    - However a quick run shows that, removing this feature result in poor result, USD 68911 which is higher then previous value, i.e. with this feature in the training. \n",
    "  - Note that the present model has an error of >USD 68K, which is not a nice result while predicting the price of a house in the range of USD 15k to 500k. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85937fc4",
   "metadata": {},
   "source": [
    "### Next steps \n",
    "Since the performance of linear regression is not convincing, there is room for improvement, both in terms of features choice and model to fit the data. Let's explore some of the models for regression and find the best for this problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61f6b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
