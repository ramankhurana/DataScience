{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bce3c45",
   "metadata": {},
   "source": [
    "# Housing price prediction \n",
    "This is second part of the California housing price prediction problem. In the first part I have explained how to perform end-to-end machine learning algorithm, and make prediction. \n",
    "\n",
    "\n",
    "\n",
    "This notebook is mainly about how to automate the preprocessing and test various models to find the best one for our case. Detailed EDA and feature enginnering is explained in the previous NB, so let's directly jump on to dataset and implement the transformers and pipeline to automate the processing post EDA. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d0b5e84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import sklearn \n",
    "from sklearn.model_selection import StratifiedShuffleSplit \n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer, OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce4752f",
   "metadata": {},
   "source": [
    "## Load Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91aa22d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"housing.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34e6b82",
   "metadata": {},
   "source": [
    "#### Stratified splitting \n",
    " - In the very begining I am using the stratified splitting for the reason explained in previous NB. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8898264",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"income_category\"] = np.ceil (df.median_income/1.5)\n",
    "df['income_category'] = df[\"income_category\"].where(df.income_category<5, 5.0)\n",
    "\n",
    "\n",
    "split = StratifiedShuffleSplit (n_splits=1, \n",
    "                       test_size=0.2,\n",
    "                       random_state=42)\n",
    "\n",
    "for train_idx, test_idx in  split.split(df, df['income_category']):\n",
    "    strat_train = df.loc[train_idx]\n",
    "    strat_test  = df.loc[test_idx]\n",
    "\n",
    "Y_train, Y_test = strat_train.median_house_value, strat_test.median_house_value\n",
    "\n",
    "for strat in strat_train, strat_test: \n",
    "    strat.drop([\"income_category\",\"median_house_value\"],axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61c82628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "       'total_bedrooms', 'population', 'households', 'median_income',\n",
       "       'ocean_proximity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf44cf2",
   "metadata": {},
   "source": [
    "## Transformer \n",
    "Let's encapsulate custom cleanup, feature engineering in a custom class which will do the job seamlessly with sklearn functionalities like pipeline etc. \n",
    " BaseEstimator, TransformerMixin are two sklearn classes which are needed to get get_param(),set_param() functions and fit_transform() respectively. \n",
    " \n",
    " - For now, check the column number in the dataframe which we need for feature engineering, we will need an automatic way to do so in future. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efb178ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin \n",
    "rooms_ix, bedrooms_ix, population_ix, household_ix = 3,4,5,6 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30385f45",
   "metadata": {},
   "source": [
    "##### Content of pipeline \n",
    "In order to preprocess the data we need to perform a series of tasks in a specific order and this can be partially done by a custom transformer class like below in collaboration with sklean pipelines as shown in following cells. \n",
    "The main tasks to be performed are: \n",
    " - cleaning of the dataset, nonnull, treatment of the missing values etc \n",
    " - adding more features based on the existing ones, \n",
    "   - numerical features \n",
    "   - treatment of the categorical features \n",
    " - scaling the columns to normalised values, using minmaxscaler or standardscaler or any other customized scaler. \n",
    " - any other task needs to be performed on the new data will enter this pipeline. \n",
    " \n",
    " Let's implement one easy pipeline for the linear regression and then use it for various models, and embrace the power of this tool. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dd32508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedroom_per_room=True): ## this does not need arga and kargs \n",
    "        self.add_bedroom_per_room = add_bedroom_per_room\n",
    "    def fit(self,X,y=None):\n",
    "        return self ## in fit function nothing else needs to be done \n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:,rooms_ix] / X[:,household_ix]\n",
    "        population_per_household = X[:,population_ix] / X[:,household_ix]\n",
    "        if self.add_bedroom_per_room:\n",
    "            bedrooms_per_room = X[:,bedrooms_ix] / X[:,rooms_ix]\n",
    "            return np.c_[X,rooms_per_household, population_per_household,bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X,rooms_per_household, population_per_household]\n",
    "\n",
    "\n",
    "attr_adder = CombinedAttributesAdder(add_bedroom_per_room=False)\n",
    "train_df_extra = attr_adder.transform(strat_train.values) ## this return a numpy 2d array. this needs to be converted to dataframe\n",
    "\n",
    "cols = strat_train.columns.tolist() +[\"rooms_per_household\",\"population_per_household\"]\n",
    "train_df_extra_  = pd.DataFrame(train_df_extra,columns=cols)\n",
    "train_df_extra_\n",
    "\n",
    "\n",
    "## This class will return the values of the Dataframe for given columns. \n",
    "## this is also a transformer \n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attributes_names):\n",
    "        self.attributes_names = attributes_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    def transform(self, X,y=None):\n",
    "        #print (\"selecting\", self.attributes_names)\n",
    "        #print (X[self.attributes_names].values.shape )\n",
    "        return X[self.attributes_names].values \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cabae612",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_cat = strat_train[[\"ocean_proximity\"]] ## only categorical features \n",
    "strat_train_num = strat_train.drop([\"ocean_proximity\"],axis=1) ## need only numerical data \n",
    "\n",
    "from sklearn.pipeline import FeatureUnion \n",
    "from sklearn.pipeline import Pipeline\n",
    "num_attr = list(strat_train_num.columns)\n",
    "cat_attr = list(strat_train_cat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "36585f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('selector',DataFrameSelector(num_attr)),\n",
    "     ('imputer',SimpleImputer (strategy=\"median\")),\n",
    "     ('add_features',CombinedAttributesAdder()),\n",
    "    ('std_scaler',StandardScaler()),\n",
    "     ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('selector',DataFrameSelector(cat_attr)),\n",
    "     ('dummies',OneHotEncoder(sparse=False)),\n",
    "     ])\n",
    "\n",
    "\n",
    "full_pipeline = FeatureUnion (transformer_list=[\n",
    "    ('num_pipeline',num_pipeline),\n",
    "    ('cat_pipeline',cat_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d243d106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.15604281,  0.77194962,  0.74333089, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.17602483,  0.6596948 , -1.1653172 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.18684903, -1.34218285,  0.18664186, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 1.58648943, -0.72478134, -1.56295222, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.78221312, -0.85106801,  0.18664186, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.43579109,  0.99645926,  1.85670895, ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline.fit_transform(strat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25e4f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dac9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
